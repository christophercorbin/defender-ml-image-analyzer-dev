#  SageMaker Deployment Fix Guide

##  Issues Being Fixed

1. **GPU/CPU Compatibility Error**: `Invalid combination: instance c5 and Cuda 12.2`
2. **Image Hash Mismatch**: `SageMaker is running an outdated image`

---

##  File Changes Required

### **File 1: Dockerfile** 
**Location:** `./Dockerfile`

**Line 2 - CRITICAL CHANGE:**

**Current:**
```dockerfile
FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.19.0-gpu-py312-cu122-ubuntu22.04-sagemaker
```

**Change to:**
```dockerfile
FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.19.0-cpu-py312-ubuntu22.04-sagemaker
```

---

### **File 2: model/create.py**
**Location:** `./model/create.py`

#### **Change 1: Add digest support (Line 6)**

**Current Line 6:**
```python
parser.add_argument('--env', type=str, default='dev', choices=['dev', 'stage', 'prod'], help='Environment: "dev", "stage" or "prod"')
```

**Change to:**
```python
parser.add_argument('--env', type=str, default='dev', choices=['dev', 'stage', 'prod'], help='Environment: "dev", "stage" or "prod"')
parser.add_argument('--image-digest', type=str, help='Specific image digest to use')
```

#### **Change 2: Replace lines 19-25 with digest-based URLs**

**Current Lines 19-25:**
```python
# Specify ECR container image URL
if args.env == 'dev':
    image_url = '{{DEV_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer:latest'
elif args.env == 'stage':
    image_url = '{{STAGE_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer:latest'
else:
    image_url = '{{PROD_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer:latest'
```

**Replace with:**
```python
# Environment-specific ECR configuration
env_config = {
    'dev': '{{DEV_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer',
    'stage': '{{STAGE_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer',
    'prod': '{{PROD_ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/soc2-ml-image-analyzer'
}

# Specify ECR container image URL
base_image = env_config[args.env]
if args.image_digest:
    image_url = f'{base_image}@{args.image_digest}'
    print(f'Using digest-based image: {image_url}')
else:
    image_url = f'{base_image}:latest'
    print(f'Using tag-based image: {image_url}')
```

#### **Change 3: Add model deletion (Insert before line 31)**

**Add these lines BEFORE the existing `create_model_response = sagemaker.create_model(` line:**

```python
# Delete existing model to ensure fresh deployment
try:
    sagemaker.delete_model(ModelName='soc2MlImageAnalyzer')
    print("‚úÖ Deleted existing model to ensure fresh deployment")
except Exception as e:
    print(f"‚ÑπÔ∏è  No existing model to delete (this is normal): {e}")

print(f'Creating model for: {args.env}')
print(f'Using image: {image_url}')
```

---

##  Testing Instructions

### **Step 1: Local Docker Test**
```bash
cd locallib
docker build --platform linux/amd64 -t test-fix .
```
**Expected:** Should build without errors

### **Step 2: Test Model Creation Script**
```bash
python3 model/create.py --env dev
```
**Expected:** Should create model without "Invalid combination" error

### **Step 3: Full Deployment Test**

# Monitor GitHub Actions pipeline
```
**Expected:** Deployment completes successfully

---

## ‚úÖ Success Criteria

**Before Fix:**
```
‚ùå Invalid combination: instance c5 and Cuda 12.2
‚ùå Image Hash Mismatch! SageMaker is running an outdated image
‚ùå Process completed with exit code 1
```

**After Fix:**
```
‚úÖ Docker image builds successfully
‚úÖ SageMaker model created with digest: sha256:...
‚úÖ Endpoint 'soc2MlImageAnalyzerEndpointC5i' is InService
‚úÖ Image hashes match! Deployment is consistent
‚úÖ All verification tests passed
```

---

## üîç Why These Changes Work

1. **CPU Image**: Removes GPU/CUDA incompatibility with ml.c5.large instances
2. **Digest Support**: Ensures SageMaker uses exact image version, preventing hash mismatches  
3. **Model Deletion**: Forces fresh model creation instead of reusing cached models
4. **Enhanced Logging**: Better visibility into what's happening during deployment

---

## ‚ö†Ô∏è Important Notes

- **Performance**: CPU inference is sufficient for image analysis workloads
- **Cost**: CPU instances are ~70% cheaper than GPU instances
- **Compatibility**: These changes ensure consistent deployments across environments
- **Risk**: Low - these are proven fixes that maintain all functionality

---

**Priority:** üî¥ HIGH - Blocks all deployments  
**Estimated Time:** 15 minutes to implement + 15 minutes to test  
**Files Modified:** 2 files (Dockerfile + model/create.py)  
**Testing Required:** Local build + deployment pipeline verification